{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e85a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Models/30.01_quaternary_model_final.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m SteeringClassifier(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Models/30.01_quaternary_model_final.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     45\u001b[0m image_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     46\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToPILImage(),\n\u001b[0;32m     47\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m                          std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[0;32m     51\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Models/30.01_quaternary_model_final.pth'"
     ]
    }
   ],
   "source": [
    "import carla\n",
    "import pygame\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from carla import VehicleLightState\n",
    "\n",
    "# Names for the 15 steering classes (left → no turn → right)\n",
    "CLASS_NAMES = [\n",
    "    \"Left Hardest\", \"Left Harder\", \"Left Hard\", \"Left Medium\", \"Left Light\", \"Left Slight\", \"Left Minimal\",\n",
    "    \"No Turning\",\n",
    "    \"Right Minimal\", \"Right Slight\", \"Right Light\", \"Right Medium\", \"Right Hard\", \"Right Harder\", \"Right Hardest\"\n",
    "]\n",
    "\n",
    "# PyTorch model: ResNet18 backbone + small head, with an embedding for turn signals\n",
    "class SteeringClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super(SteeringClassifier, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()  # drop the final FC to use raw 512-d features\n",
    "        self.cnn = resnet\n",
    "        self.turn_embed = nn.Embedding(3, 16)  # turn signals -1/0/1 mapped to 0/1/2\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 + 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, turn_signal):\n",
    "        x_img = self.cnn(image)\n",
    "        x_signal = self.turn_embed(turn_signal)\n",
    "        x = torch.cat((x_img, x_signal), dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Load the trained model and set it to eval mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SteeringClassifier(num_classes=15)\n",
    "model.load_state_dict(torch.load(\"../Models/30.01_quaternary_model_final.pth\", map_location=device))\n",
    "model.eval().to(device)\n",
    "\n",
    "# Basic image preprocessing to 224x224 with ImageNet normalization\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Spin up a Pygame window to visualize the drive\n",
    "pygame.init()\n",
    "width, height = 800, 600\n",
    "screen = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption(\"CARLA Model-Controlled Driving\")\n",
    "\n",
    "# Connect to CARLA and load Town05\n",
    "client = carla.Client(\"localhost\", 2000)\n",
    "client.set_timeout(25.0)\n",
    "client.load_world(\"Town05\")\n",
    "world = client.get_world()\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "\n",
    "# Spawn a Dodge Charger and keep control manual (no autopilot)\n",
    "vehicle_bp = blueprint_library.filter(\"vehicle.dodge.charger_2020\")[0]\n",
    "spawn_point = random.choice(world.get_map().get_spawn_points())\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "vehicle.set_autopilot(False)\n",
    "\n",
    "# We’ll use the spectator to follow the car from behind\n",
    "spectator = world.get_spectator()\n",
    "\n",
    "# Add a front RGB camera to the car\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '448')\n",
    "camera_bp.set_attribute('image_size_y', '252')\n",
    "camera_bp.set_attribute('fov', '145')\n",
    "camera_bp.set_attribute('sensor_tick', '0.1')\n",
    "cam_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "camera = world.spawn_actor(camera_bp, cam_transform, attach_to=vehicle)\n",
    "\n",
    "# Shared state: latest frame (as Pygame surface + NumPy) and current label text\n",
    "camera_image = None\n",
    "camera_np = None\n",
    "pred_label = \"Loading...\"\n",
    "\n",
    "def process_image(image):\n",
    "    # Convert raw CARLA bytes to RGB numpy, keep a copy for inference, and a scaled surface for display\n",
    "    global camera_image, camera_np\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    array = array.reshape((image.height, image.width, 4))\n",
    "    array = array[:, :, :3][:, :, ::-1]  # BGRA → RGB\n",
    "    camera_np = array.copy()\n",
    "    camera_image_raw = pygame.surfarray.make_surface(array.swapaxes(0, 1))\n",
    "    camera_image = pygame.transform.scale(camera_image_raw, (800, 600))\n",
    "\n",
    "# Start streaming frames to our callback\n",
    "camera.listen(process_image)\n",
    "\n",
    "# Simple timing helper for the main loop\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "print(\"Model-controlled driving started.\")\n",
    "print(\"Q/E to turn on left/right signal, R to cancel.\")\n",
    "print(\"ESC or close window to exit.\")\n",
    "\n",
    "# Map each of the 15 classes to a steering value (-1.0 left to +1.0 right)\n",
    "steering_map = {\n",
    "    0: -0.8,   1: -0.6,   2: -0.4,   3: -0.25,   4: -0.20,  5: -0.1,  6: -0.05,\n",
    "    7:  0.0,\n",
    "    8:  0.05,  9:  0.1, 10:  0.15, 11:  0.25,  12:  0.4,  13:  0.6,  14:  0.8\n",
    "}\n",
    "\n",
    "def respawn_vehicle():\n",
    "    # Tear down the current actors and bring the car back somewhere new\n",
    "    global vehicle, camera\n",
    "\n",
    "    if camera.is_listening:\n",
    "        camera.stop()\n",
    "    camera.destroy()\n",
    "    vehicle.destroy()\n",
    "\n",
    "    # Drop the car at a new spawn point\n",
    "    spawn_point = random.choice(world.get_map().get_spawn_points())\n",
    "    vehicle_new = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    vehicle_new.set_autopilot(False)\n",
    "\n",
    "    # Re-attach the camera and listen again\n",
    "    camera_new = world.spawn_actor(camera_bp, cam_transform, attach_to=vehicle_new)\n",
    "    camera_new.listen(process_image)\n",
    "\n",
    "    vehicle = vehicle_new\n",
    "    camera = camera_new\n",
    "\n",
    "# Start with a modest throttle; we’ll nudge it with W/S\n",
    "throttle = 0.3\n",
    "\n",
    "# Main control loop: read inputs, run the model, and apply controls\n",
    "try:\n",
    "    while True:\n",
    "        clock.tick(60)\n",
    "        pygame.event.pump()\n",
    "        keys = pygame.key.get_pressed()\n",
    "\n",
    "        # Turn signals via Q/E, cancel with R; otherwise keep current light state\n",
    "        if keys[pygame.K_q]:\n",
    "            vehicle.set_light_state(VehicleLightState.LeftBlinker)\n",
    "            turn_signal = -1\n",
    "        elif keys[pygame.K_e]:\n",
    "            vehicle.set_light_state(VehicleLightState.RightBlinker)\n",
    "            turn_signal = 1\n",
    "        elif keys[pygame.K_r]:\n",
    "            vehicle.set_light_state(VehicleLightState.NONE)\n",
    "            turn_signal = 0\n",
    "        else:\n",
    "            light_state = vehicle.get_light_state()\n",
    "            if light_state == VehicleLightState.LeftBlinker:\n",
    "                turn_signal = -1\n",
    "            elif light_state == VehicleLightState.RightBlinker:\n",
    "                turn_signal = 1\n",
    "            else:\n",
    "                turn_signal = 0\n",
    "\n",
    "        # Manual throttle tweaks: W to speed up, S to ease off (with a floor)\n",
    "        if keys[pygame.K_w]:\n",
    "            throttle += 0.005\n",
    "        if keys[pygame.K_s]:\n",
    "            if throttle > 0.1:\n",
    "                throttle -= 0.005\n",
    "\n",
    "        # Hit P to respawn the car and reset throttle\n",
    "        if keys[pygame.K_p]:\n",
    "            print(\"Respawning vehicle...\")\n",
    "            respawn_vehicle()\n",
    "            throttle = 0.3\n",
    "            time.sleep(1)  # small debounce so holding P doesn’t spam respawns\n",
    "            continue\n",
    "\n",
    "        # Build control each frame and apply throttle\n",
    "        control = carla.VehicleControl()\n",
    "        control.throttle = throttle\n",
    "\n",
    "        # Basic smoothing/hold logic for steering updates\n",
    "        prev_steering_value = 0.0\n",
    "        last_steering_time = time.time()\n",
    "        STEERING_HOLD_S = 0.05  # 50 ms\n",
    "\n",
    "        if camera_np is not None:\n",
    "            with torch.no_grad():\n",
    "                img = image_transform(camera_np).unsqueeze(0).to(device)\n",
    "                signal = torch.tensor([[turn_signal + 1]], dtype=torch.long).to(device)\n",
    "                output = model(img, signal.squeeze(1))\n",
    "                pred_class = output.argmax(dim=1).item()\n",
    "                pred_label = CLASS_NAMES[pred_class]\n",
    "                steering_value = steering_map[pred_class]\n",
    "\n",
    "                # If a blinker is on, don’t allow a near-zero steering suggestion\n",
    "                if turn_signal == -1 and steering_value > -0.02:\n",
    "                    steering_value = -0.02\n",
    "                elif turn_signal == 1 and steering_value < 0.02:\n",
    "                    steering_value = 0.02\n",
    "\n",
    "                # Apply steering with a tiny bit of smoothing/holding\n",
    "                current_time = time.time()\n",
    "\n",
    "                if steering_value == 0.0 or prev_steering_value == 0.0:\n",
    "                    # For zeros (new or previous), just set it directly\n",
    "                    control.steer = steering_value\n",
    "                    prev_steering_value = steering_value\n",
    "                    last_steering_time = current_time\n",
    "                elif steering_value != prev_steering_value:\n",
    "                    # New nonzero suggestion → average with previous for mild smoothing\n",
    "                    smoothed_value = (steering_value + prev_steering_value) / 2\n",
    "                    control.steer = smoothed_value\n",
    "                    prev_steering_value = steering_value\n",
    "                    last_steering_time = current_time\n",
    "                else:\n",
    "                    # Same nonzero value → hold it for a short window\n",
    "                    if current_time - last_steering_time >= STEERING_HOLD_S:\n",
    "                        control.steer = steering_value\n",
    "\n",
    "        # Apply control to the vehicle\n",
    "        vehicle.apply_control(control)\n",
    "\n",
    "        # Keep the spectator camera trailing the car from above/behind\n",
    "        car_transform = vehicle.get_transform()\n",
    "        forward_vector = car_transform.get_forward_vector()\n",
    "        cam_location = car_transform.location - forward_vector * 8 + carla.Location(z=3)\n",
    "        cam_rotation = carla.Rotation(pitch=-10, yaw=car_transform.rotation.yaw)\n",
    "        spectator.set_transform(carla.Transform(cam_location, cam_rotation))\n",
    "\n",
    "        # Draw the camera feed and some HUD text\n",
    "        if camera_image:\n",
    "            screen.blit(camera_image, (0, 0))\n",
    "            font = pygame.font.SysFont(None, 30)\n",
    "            label_turn = font.render(f\"Predicted: {pred_label}\", True, (255, 255, 0))\n",
    "            label_steer = font.render(f\"Steering: {steering_value:.3f}\", True, (0, 255, 0))\n",
    "            label_speed = font.render(f\"Throttle: {throttle:.1f}\", True, (0, 200, 255))\n",
    "\n",
    "            screen.blit(label_turn, (20, 20))\n",
    "            screen.blit(label_steer, (20, 50))\n",
    "            screen.blit(label_speed, (20, 80))\n",
    "\n",
    "            pygame.display.flip()\n",
    "\n",
    "        # Quit with the window button or ESC\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT or keys[pygame.K_ESCAPE]:\n",
    "                raise KeyboardInterrupt\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting and cleaning up...\")\n",
    "\n",
    "finally:\n",
    "    camera.stop()\n",
    "    vehicle.destroy()\n",
    "    camera.destroy()\n",
    "    pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
