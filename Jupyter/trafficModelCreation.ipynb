{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4852d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: NVIDIA GeForce RTX 4060 Laptop GPU (CUDA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pravi\\AppData\\Local\\Temp\\ipykernel_8956\\3858488188.py:130: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n"
     ]
    }
   ],
   "source": [
    "# traffic classifier model creation (3 classes: -1=no light, 0=red, 1=green)\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Config\n",
    "IMAGES_PATH = \"../output/traffic_lights_images.npy\"\n",
    "LABELS_PATH = \"../output/traffic_lights_label.npy\"\n",
    "SAVE_DIR = \"../Models\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LR = 3e-5\n",
    "VAL_SPLIT = 0.2\n",
    "RESIZE = 224\n",
    "SEED = 42\n",
    "USE_PRETRAINED = True\n",
    "MEAN = (0.485, 0.456, 0.406)\n",
    "STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "# Label mapping: {-1, 0, 1} -> {0, 1, 2} for training; decode back for output\n",
    "LABEL_MAP = {-1: 0, 0: 1, 1: 2}\n",
    "INV_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "NUM_CLASSES = len(LABEL_MAP)\n",
    "\n",
    "# Seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Dataset loader for .npy files\n",
    "class NpyImageDataset(Dataset):\n",
    "    def __init__(self, images_path, labels_path, transform=None, label_map=None):\n",
    "        self.images = np.load(images_path, mmap_mode='r')\n",
    "        self.labels = np.load(labels_path, mmap_mode='r')\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map or (lambda x: x)\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        arr = self.images[idx]\n",
    "        if arr.dtype != np.uint8:\n",
    "            arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
    "        img = transforms.functional.to_pil_image(arr)\n",
    "        x = self.transform(img) if self.transform else transforms.ToTensor()(img)\n",
    "\n",
    "        raw_label = int(self.labels[idx])\n",
    "        if raw_label not in LABEL_MAP:\n",
    "            raise ValueError(f\"Unexpected label {raw_label}; expected one of {list(LABEL_MAP.keys())}\")\n",
    "        y = LABEL_MAP[raw_label]  # map to {0,1,2}\n",
    "        return x, y\n",
    "\n",
    "# Build ResNet18\n",
    "def build_model(num_classes=NUM_CLASSES, pretrained=True):\n",
    "    try:\n",
    "        weights = models.ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        model = models.resnet18(weights=weights)\n",
    "    except:\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Evaluate helper\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    losses, correct, total = [], 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            losses.append(F.cross_entropy(logits, yb).item())\n",
    "            correct += (logits.argmax(1) == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return float(np.mean(losses) if losses else 0.0), correct / max(total, 1)\n",
    "\n",
    "# Training loop\n",
    "def main():\n",
    "    set_seed(SEED)\n",
    "    if not Path(IMAGES_PATH).exists() or not Path(LABELS_PATH).exists():\n",
    "        raise FileNotFoundError(\"Check IMAGES_PATH and LABELS_PATH\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Using device: {device}\")  # <-- Added print here\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"Using device: {torch.cuda.get_device_name(0)} (CUDA)\")\n",
    "    else:\n",
    "        print(\"Using device: CPU\")\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        transforms.Resize((RESIZE, RESIZE)),\n",
    "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.02),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ])\n",
    "    val_tfms = transforms.Compose([\n",
    "        transforms.Resize((RESIZE, RESIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ])\n",
    "\n",
    "    # Split data (stratify on *mapped* labels)\n",
    "    full_ds = NpyImageDataset(IMAGES_PATH, LABELS_PATH)\n",
    "    raw_labels = np.array([int(x) for x in full_ds.labels])\n",
    "    if not np.all(np.isin(raw_labels, list(LABEL_MAP.keys()))):\n",
    "        bad = raw_labels[~np.isin(raw_labels, list(LABEL_MAP.keys()))]\n",
    "        raise ValueError(f\"Found unexpected labels: {np.unique(bad)}; expected {list(LABEL_MAP.keys())}\")\n",
    "    mapped_labels = np.vectorize(LABEL_MAP.get)(raw_labels)\n",
    "\n",
    "    idx_train, idx_val = train_test_split(\n",
    "        np.arange(len(full_ds)), test_size=VAL_SPLIT, stratify=mapped_labels, random_state=SEED\n",
    "    )\n",
    "    train_ds = Subset(NpyImageDataset(IMAGES_PATH, LABELS_PATH, transform=train_tfms), idx_train)\n",
    "    val_ds = Subset(NpyImageDataset(IMAGES_PATH, LABELS_PATH, transform=val_tfms), idx_val)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=(device.type=='cuda'))\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=2, pin_memory=(device.type=='cuda'))\n",
    "\n",
    "    model = build_model(pretrained=USE_PRETRAINED).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "    best_acc = 0.0\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    best_path = os.path.join(SAVE_DIR, 'traffic_lights_model.pt')\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        losses, correct, total = [], 0, 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
    "                logits = model(xb)\n",
    "                loss = F.cross_entropy(logits, yb)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            losses.append(loss.item())\n",
    "            correct += (logits.argmax(1) == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch:02d} | Train Acc {correct/max(total,1):.4f} | Val Acc {val_acc:.4f} | Val Loss {val_loss:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save({'model_state_dict': model.state_dict()}, best_path)\n",
    "            print(f\"  Saved new best model (val_acc={best_acc:.4f})\")\n",
    "\n",
    "    print(f\"Training done. Best val_acc={best_acc:.4f}\")\n",
    "\n",
    "# Quick prediction helper (returns -1, 0, or 1)\n",
    "def predict(image_array, weights_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = build_model(pretrained=False).to(device)\n",
    "    state = torch.load(weights_path, map_location=device)\n",
    "    model.load_state_dict(state['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    if image_array.dtype != np.uint8:\n",
    "        image_array = np.clip(image_array, 0, 255).astype(np.uint8)\n",
    "    img = transforms.functional.to_pil_image(image_array)\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((RESIZE, RESIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ])\n",
    "    x = tfm(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        mapped_pred = int(logits.argmax(1).item())   # in {0,1,2}\n",
    "        pred = int(INV_LABEL_MAP[mapped_pred])       # back to {-1,0,1}\n",
    "    return pred\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
