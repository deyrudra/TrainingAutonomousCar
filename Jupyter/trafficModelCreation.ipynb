{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb4852d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 111\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected images with 3 or 4 dims (N,H,W[,C]); got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# >>> Apply traffic_light_crop to every image BEFORE any channel moves/normalization\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([traffic_light_crop(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X], dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Channel-first\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "Cell \u001b[1;32mIn[17], line 111\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected images with 3 or 4 dims (N,H,W[,C]); got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# >>> Apply traffic_light_crop to every image BEFORE any channel moves/normalization\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtraffic_light_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X], dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Channel-first\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "Cell \u001b[1;32mIn[17], line 60\u001b[0m, in \u001b[0;36mtraffic_light_crop\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     57\u001b[0m h, w \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# ---- Center zoom ----\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m new_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(w \u001b[38;5;241m/\u001b[39m \u001b[43mz\u001b[49m))\n\u001b[0;32m     61\u001b[0m new_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(h \u001b[38;5;241m/\u001b[39m z))\n\u001b[0;32m     62\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, (w \u001b[38;5;241m-\u001b[39m new_w) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "# traffic_classifier_resnet.py\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import cv2\n",
    "\n",
    "# --------------------\n",
    "# Reproducibility\n",
    "# --------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --------------------\n",
    "# Paths\n",
    "# --------------------\n",
    "IMAGES_PATH = \"../output/traffic_lights_images.npy\"\n",
    "LABELS_PATH = \"../output/traffic_lights_label.npy\"\n",
    "SAVE_DIR = \"../Models\"\n",
    "CKPT_DIR = os.path.join(SAVE_DIR, \"checkpoints\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "# Checkpoint cadence\n",
    "SAVE_EVERY = 2  # set 0 to disable periodic epoch_XXX saves\n",
    "\n",
    "# --------------------\n",
    "# cuDNN speedups\n",
    "# --------------------\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "def traffic_light_crop(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Black out the bottom third, blur and desaturate the left & right quarters.\n",
    "    Works for (H, W) grayscale or (H, W, C) RGB images.\n",
    "    Returns a copy with same shape/dtype.\n",
    "    \"\"\"\n",
    "    if img is None or img.ndim not in (2, 3):\n",
    "        return img\n",
    "\n",
    "    out = img.copy()\n",
    "    h, w = out.shape[:2]\n",
    "\n",
    "    # ---- Center zoom ----\n",
    "    new_w = max(1, int(w / z))\n",
    "    new_h = max(1, int(h / z))\n",
    "    x1 = max(0, (w - new_w) // 2)\n",
    "    y1 = max(0, (h - new_h) // 2)\n",
    "    cropped = out[y1:y1 + new_h, x1:x1 + new_w]\n",
    "    if cropped.size > 0:\n",
    "        out = cv2.resize(cropped, (w, h))\n",
    "\n",
    "    # --- Blackout bottom third ---\n",
    "    out[h * 2 // 3 :, ...] = 0\n",
    "\n",
    "    # --- Prepare for color manipulation ---\n",
    "    is_gray = (out.ndim == 2) or (out.shape[2] == 1)\n",
    "    if is_gray:\n",
    "        # Expand grayscale to 3 channels for consistent processing\n",
    "        out_rgb = cv2.cvtColor(out, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        out_rgb = out\n",
    "\n",
    "    quarter_w = max(1, w // 4)\n",
    "\n",
    "    def blur_and_desaturate(region: np.ndarray) -> np.ndarray:\n",
    "        blurred = cv2.GaussianBlur(region, (21, 21), 0)\n",
    "        # hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "        # hsv[:, :, 1] = 0\n",
    "        # desat = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        return blurred\n",
    "    \n",
    "    # Left strip\n",
    "    out_rgb[:, :quarter_w, :] = blur_and_desaturate(out_rgb[:, :quarter_w, :])\n",
    "    # Right strip\n",
    "    out_rgb[:, -quarter_w:, :] = blur_and_desaturate(out_rgb[:, -quarter_w:, :])\n",
    "\n",
    "    # If original was grayscale, convert back\n",
    "    if is_gray:\n",
    "        out_final = cv2.cvtColor(out_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        out_final = out_rgb\n",
    "\n",
    "    return out_final\n",
    "\n",
    "# --------------------\n",
    "# Load data (NumPy)\n",
    "# --------------------\n",
    "X = np.load(IMAGES_PATH)  # (N,H,W) or (N,H,W,C)\n",
    "y_raw = np.load(LABELS_PATH)  # (N,) in {-1,0,1}\n",
    "\n",
    "if X.ndim not in (3, 4):\n",
    "    raise ValueError(f\"Expected images with 3 or 4 dims (N,H,W[,C]); got {X.shape}\")\n",
    "\n",
    "# >>> Apply traffic_light_crop to every image BEFORE any channel moves/normalization\n",
    "X = np.array([traffic_light_crop(x) for x in X], dtype=X.dtype)\n",
    "\n",
    "# Channel-first\n",
    "if X.ndim == 3:\n",
    "    X = np.expand_dims(X, axis=1)             # (N,1,H,W)\n",
    "else:\n",
    "    X = np.transpose(X, (0, 3, 1, 2))         # (N,C,H,W)\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "if X.max() > 1.5:\n",
    "    X /= 255.0\n",
    "\n",
    "# Labels {-1,0,1} -> {0,1,2}\n",
    "label_to_index = {-1: 0, 0: 1, 1: 2}\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "try:\n",
    "    y = np.vectorize(label_to_index.__getitem__)(y_raw)\n",
    "except KeyError as e:\n",
    "    raise ValueError(f\"Unknown label {e}; expected only -1, 0, 1\")\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# --------------------\n",
    "# Tensors\n",
    "# --------------------\n",
    "X_torch = torch.from_numpy(X).contiguous()                    # (N,C,H,W) float32\n",
    "y_torch = torch.from_numpy(y.astype(np.int64)).contiguous()   # (N,)\n",
    "\n",
    "# --------------------\n",
    "# Stratified split (80/20)\n",
    "# --------------------\n",
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    X_torch.numpy(), y_torch.numpy(),\n",
    "    test_size=0.2, random_state=SEED, stratify=y_torch.numpy(), shuffle=True\n",
    ")\n",
    "X_train = torch.from_numpy(X_train_np).contiguous()\n",
    "X_val   = torch.from_numpy(X_val_np).contiguous()\n",
    "y_train = torch.from_numpy(y_train_np).contiguous()\n",
    "y_val   = torch.from_numpy(y_val_np).contiguous()\n",
    "\n",
    "# --------------------\n",
    "# Transforms (RGB, 224, flip/rotate, cutout, ImageNet norm)\n",
    "# --------------------\n",
    "def to_rgb_tensor(x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (C,H,W) float in [0,1]\n",
    "    if x.dim() != 3:\n",
    "        raise ValueError(f\"Expected (C,H,W), got {tuple(x.shape)}\")\n",
    "    if x.shape[0] == 1:  # gray -> RGB\n",
    "        x = x.repeat(3, 1, 1)\n",
    "    elif x.shape[0] != 3:\n",
    "        raise ValueError(f\"Unsupported channels: {x.shape[0]}, expected 1 or 3.\")\n",
    "    return x\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Lambda(to_rgb_tensor),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=10, interpolation=InterpolationMode.BILINEAR, expand=False),\n",
    "    T.ToTensor(),\n",
    "    # blackout/cutout (chain for occasional multiple holes)\n",
    "    T.RandomErasing(p=0.5, scale=(0.02, 0.12), ratio=(0.3, 3.3), value=0.0, inplace=False),\n",
    "    T.RandomErasing(p=0.25, scale=(0.01, 0.06), ratio=(0.3, 3.3), value=0.0, inplace=False),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Lambda(to_rgb_tensor),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# --------------------\n",
    "# Dataset wrapper\n",
    "# --------------------\n",
    "class AugmentedTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors, transform=None):\n",
    "        super().__init__(*tensors); self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        *xs, y = super().__getitem__(index)\n",
    "        x = xs[0]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "# --------------------\n",
    "# DataLoaders (Windows/Jupyter safe)\n",
    "# --------------------\n",
    "def _workers():\n",
    "    is_windows = (os.name == \"nt\")\n",
    "    is_interactive = (\"ipykernel\" in sys.modules)\n",
    "    if is_windows or is_interactive:\n",
    "        return 0\n",
    "    c = os.cpu_count() or 2\n",
    "    return max(min(4, c - 1), 0)\n",
    "\n",
    "num_workers = _workers()\n",
    "persistent = True if num_workers > 0 else False\n",
    "\n",
    "train_ds = AugmentedTensorDataset(X_train, y_train, transform=train_transform)\n",
    "val_ds   = AugmentedTensorDataset(X_val,   y_val,   transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=64, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=True, persistent_workers=persistent\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=64, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=True, persistent_workers=persistent\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# Model: ResNet-18 wrapped in ResNetClassifier (so keys are \"net.*\")\n",
    "# --------------------\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)  # expects 3ch\n",
    "        in_feat = backbone.fc.in_features\n",
    "        backbone.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_feat, num_classes))\n",
    "        self.net = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --------------------\n",
    "# Device & AMP\n",
    "# --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"AMP enabled:\", torch.cuda.is_available())\n",
    "\n",
    "model = ResNetClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "# --------------------\n",
    "# Loss / Optim / Scheduler\n",
    "# --------------------\n",
    "ctr = Counter(y_train.tolist())\n",
    "counts = np.array([ctr.get(i, 0) for i in range(num_classes)], dtype=np.float32)\n",
    "if np.any(counts == 0):\n",
    "    class_weights = None\n",
    "else:\n",
    "    inv = 1.0 / counts\n",
    "    class_weights = torch.tensor(inv / inv.sum() * num_classes, dtype=torch.float32, device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
    "\n",
    "# two lrs: backbone vs head\n",
    "head_params = list(model.net.fc.parameters())\n",
    "backbone_params = [p for n, p in model.net.named_parameters() if not n.startswith(\"fc.\")]\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 1e-4},\n",
    "        {\"params\": head_params,     \"lr\": 3e-4},\n",
    "    ],\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "# --------------------\n",
    "# Checkpoint helpers\n",
    "# --------------------\n",
    "def _checkpoint_payload(epoch:int, best_val_loss:float, best_val_acc:float):\n",
    "    return {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"val_loss\": float(best_val_loss),\n",
    "        \"val_acc\": float(best_val_acc),\n",
    "        \"num_classes\": int(num_classes),\n",
    "        \"label_to_index\": label_to_index,\n",
    "        \"index_to_label\": index_to_label,\n",
    "        \"imagenet_mean\": IMAGENET_MEAN,\n",
    "        \"imagenet_std\": IMAGENET_STD,\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    "\n",
    "def save_last(epoch, best_val_loss, best_val_acc):\n",
    "    path = os.path.join(CKPT_DIR, \"last.pth\")\n",
    "    torch.save(_checkpoint_payload(epoch, best_val_loss, best_val_acc), path)\n",
    "    print(f\"[ckpt] Saved last -> {path}\")\n",
    "\n",
    "def save_best(epoch, best_val_loss, best_val_acc):\n",
    "    path = os.path.join(CKPT_DIR, \"best.pth\")\n",
    "    torch.save(_checkpoint_payload(epoch, best_val_loss, best_val_acc), path)\n",
    "    print(f\"[ckpt] ✅ New best (val_loss={best_val_loss:.4f}) -> {path}\")\n",
    "\n",
    "def save_periodic(epoch, best_val_loss, best_val_acc):\n",
    "    if SAVE_EVERY and (epoch % SAVE_EVERY == 0):\n",
    "        path = os.path.join(CKPT_DIR, f\"epoch_{epoch:03d}.pth\")\n",
    "        torch.save(_checkpoint_payload(epoch, best_val_loss, best_val_acc), path)\n",
    "        print(f\"[ckpt] Saved periodic -> {path}\")\n",
    "\n",
    "# --------------------\n",
    "# Eval\n",
    "# --------------------\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total, correct, run_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "            run_loss += loss.item() * yb.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return run_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "# --------------------\n",
    "# Train\n",
    "# --------------------\n",
    "EPOCHS = 15\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state = None\n",
    "es_patience = 6\n",
    "es_wait = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    run_loss = 0.0; seen = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device, non_blocking=True); yb = yb.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        run_loss += loss.item() * yb.size(0); seen += yb.size(0)\n",
    "\n",
    "    train_loss = run_loss / max(seen, 1)\n",
    "    val_loss, val_acc = evaluate(val_loader)\n",
    "\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"[LR] reduced: {old_lr:.6g} -> {new_lr:.6g}\")\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | val_acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save \"last\" every epoch + periodic snapshots\n",
    "    save_last(epoch, best_val_loss, best_val_acc)\n",
    "    save_periodic(epoch, best_val_loss, best_val_acc)\n",
    "\n",
    "    # Track & save best\n",
    "    if val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        best_state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"val_acc\": float(val_acc),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"num_classes\": int(num_classes),\n",
    "        }\n",
    "        save_best(epoch, best_val_loss, best_val_acc)\n",
    "        es_wait = 0\n",
    "    else:\n",
    "        es_wait += 1\n",
    "        if es_wait >= es_patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (no val_loss improvement for {es_patience} epochs).\")\n",
    "            break\n",
    "\n",
    "# --------------------\n",
    "# Final eval\n",
    "# --------------------\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state[\"model_state_dict\"])\n",
    "final_val_loss, final_val_acc = evaluate(val_loader)\n",
    "print(f\"Best validation loss:     {best_val_loss:.4f}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Final validation loss:    {final_val_loss:.4f}\")\n",
    "print(f\"Final validation accuracy:{final_val_acc:.4f}\")\n",
    "\n",
    "# --------------------\n",
    "# Save artifacts (keys start with 'net.' -> matches testing script)\n",
    "# --------------------\n",
    "pth_path = os.path.join(SAVE_DIR, \"traffic_classifier_state.pth\")\n",
    "torch.save(best_state if best_state is not None else model.state_dict(), pth_path)\n",
    "print(f\"Saved state to: {pth_path}\")\n",
    "\n",
    "# TorchScript (scripted model expects 3x224x224 normalized)\n",
    "# Build a normalized example via val_transform\n",
    "ex = val_transform(X_val[:1].squeeze(0) if X_val[:1].ndim == 4 else X_val[:1])\n",
    "example = ex.unsqueeze(0).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scripted = torch.jit.trace(model, example)\n",
    "ts_path = os.path.join(SAVE_DIR, \"traffic_classifier_scripted.pt\")\n",
    "scripted.save(ts_path)\n",
    "print(f\"Saved TorchScript model to: {ts_path}\")\n",
    "\n",
    "# Class mapping & metrics\n",
    "with open(os.path.join(SAVE_DIR, \"class_mapping.json\"), \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"index_to_label\": {str(k): int(v) for k, v in index_to_label.items()},\n",
    "            \"label_to_index\": {str(k): int(v) for k, v in label_to_index.items()},\n",
    "            \"semantics\": {\"-1\": \"no light\", \"0\": \"red\", \"1\": \"green\"}\n",
    "        },\n",
    "        f,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"metrics.txt\"), \"w\") as f:\n",
    "    f.write(f\"Final validation accuracy: {final_val_acc:.4f}\\n\")\n",
    "    f.write(f\"Final validation loss: {final_val_loss:.4f}\\n\")\n",
    "    f.write(f\"Best validation accuracy: {best_val_acc:.4f}\\n\")\n",
    "    f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\")\n",
    "\n",
    "# --------------------\n",
    "# Prediction helper (applies same val pipeline)\n",
    "# --------------------\n",
    "def predict_labels_numpy(np_batch: np.ndarray, batch_size: int = 128) -> np.ndarray:\n",
    "    model.eval()\n",
    "    if np_batch.ndim == 3:\n",
    "        np_batch = np.expand_dims(np_batch, axis=0)\n",
    "    if np_batch.shape[-1] in (1,3) and np_batch.shape[1] not in (1,3):\n",
    "        np_batch = np.transpose(np_batch, (0,3,1,2))\n",
    "    if np_batch.dtype != np.float32:\n",
    "        np_batch = np_batch.astype(\"float32\")\n",
    "    if np_batch.max() > 1.5:\n",
    "        np_batch /= 255.0\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, np_batch.shape[0], batch_size):\n",
    "            chunk = torch.from_numpy(np_batch[i:i+batch_size])\n",
    "            batch_t = [val_transform(x) for x in chunk]  # ensure RGB+224+norm\n",
    "            batch_t = torch.stack(batch_t, dim=0).to(device, non_blocking=True)\n",
    "            logits = model(batch_t)\n",
    "            preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return np.vectorize(index_to_label.__getitem__)(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14570dc4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e459cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled class counts (this epoch): [835, 848, 814]  [order: index 0=-1 (no), 1=0 (red), 2=1 (green)]\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce GTX 1060 6GB\n",
      "AMP enabled: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:297: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.847, red=0.792, green=0.782 | macro=0.807\n",
      "Epoch 01/15 | train_loss: 0.8714 | val_loss: 0.5925 | val_acc: 0.8048 | val_macro: 0.8068\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] ✅ New best (val_loss=0.5925) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.952, red=0.903, green=0.852 | macro=0.902\n",
      "Epoch 02/15 | train_loss: 0.4872 | val_loss: 0.4246 | val_acc: 0.8992 | val_macro: 0.9024\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] Saved periodic -> ../Models\\checkpoints\\epoch_002.pth\n",
      "[ckpt] ✅ New best (val_loss=0.4246) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.958, red=0.903, green=0.913 | macro=0.925\n",
      "Epoch 03/15 | train_loss: 0.3585 | val_loss: 0.3693 | val_acc: 0.9232 | val_macro: 0.9246\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] ✅ New best (val_loss=0.3693) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.984, red=0.961, green=0.921 | macro=0.956\n",
      "Epoch 04/15 | train_loss: 0.3129 | val_loss: 0.3038 | val_acc: 0.9536 | val_macro: 0.9556\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] Saved periodic -> ../Models\\checkpoints\\epoch_004.pth\n",
      "[ckpt] ✅ New best (val_loss=0.3038) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.989, red=0.971, green=0.965 | macro=0.975\n",
      "Epoch 05/15 | train_loss: 0.2936 | val_loss: 0.2619 | val_acc: 0.9744 | val_macro: 0.9752\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] ✅ New best (val_loss=0.2619) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.963, red=0.971, green=0.974 | macro=0.969\n",
      "Epoch 06/15 | train_loss: 0.2824 | val_loss: 0.2823 | val_acc: 0.9696 | val_macro: 0.9693\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] Saved periodic -> ../Models\\checkpoints\\epoch_006.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.968, red=0.957, green=0.956 | macro=0.960\n",
      "Epoch 07/15 | train_loss: 0.2642 | val_loss: 0.2721 | val_acc: 0.9600 | val_macro: 0.9604\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=1.000, red=0.976, green=0.948 | macro=0.974\n",
      "Epoch 08/15 | train_loss: 0.2529 | val_loss: 0.2617 | val_acc: 0.9728 | val_macro: 0.9745\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] Saved periodic -> ../Models\\checkpoints\\epoch_008.pth\n",
      "[ckpt] ✅ New best (val_loss=0.2617) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.995, red=0.971, green=0.991 | macro=0.986\n",
      "Epoch 09/15 | train_loss: 0.2441 | val_loss: 0.2377 | val_acc: 0.9856 | val_macro: 0.9857\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] ✅ New best (val_loss=0.2377) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=1.000, red=0.971, green=0.983 | macro=0.985\n",
      "Epoch 10/15 | train_loss: 0.2494 | val_loss: 0.2305 | val_acc: 0.9840 | val_macro: 0.9845\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] Saved periodic -> ../Models\\checkpoints\\epoch_010.pth\n",
      "[ckpt] ✅ New best (val_loss=0.2305) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.995, red=0.990, green=0.991 | macro=0.992\n",
      "Epoch 11/15 | train_loss: 0.2269 | val_loss: 0.2278 | val_acc: 0.9920 | val_macro: 0.9921\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] ✅ New best (val_loss=0.2278) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=0.974, red=0.990, green=0.987 | macro=0.984\n",
      "Epoch 12/15 | train_loss: 0.2302 | val_loss: 0.2322 | val_acc: 0.9840 | val_macro: 0.9836\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] Saved periodic -> ../Models\\checkpoints\\epoch_012.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=1.000, red=0.981, green=0.978 | macro=0.986\n",
      "Epoch 13/15 | train_loss: 0.2257 | val_loss: 0.2323 | val_acc: 0.9856 | val_macro: 0.9863\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=1.000, red=0.981, green=0.978 | macro=0.986\n",
      "Epoch 14/15 | train_loss: 0.2199 | val_loss: 0.2228 | val_acc: 0.9856 | val_macro: 0.9863\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n",
      "[ckpt] Saved periodic -> ../Models\\checkpoints\\epoch_014.pth\n",
      "[ckpt] ✅ New best (val_loss=0.2228) -> ../Models\\checkpoints\\best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=1.000, red=0.976, green=0.974 | macro=0.983\n",
      "Epoch 15/15 | train_loss: 0.2137 | val_loss: 0.2241 | val_acc: 0.9824 | val_macro: 0.9832\n",
      "[ckpt] Saved last -> ../Models\\checkpoints\\last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deyru\\AppData\\Local\\Temp\\ipykernel_16768\\1260994727.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class acc: no light=1.000, red=0.976, green=0.974 | macro=0.983\n",
      "Best validation loss:     0.2228\n",
      "Best validation accuracy: 0.9856\n",
      "Final validation loss:    0.2241\n",
      "Final validation accuracy:0.9824\n",
      "Final per-class acc: no-light=1.0000, red=0.9758, green=0.9738 | macro=0.9832\n",
      "Saved state to: ../Models\\traffic_classifier_state.pth\n",
      "Saved TorchScript model to: ../Models\\traffic_classifier_scripted.pt\n"
     ]
    }
   ],
   "source": [
    "# traffic_classifier_resnet.py\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import cv2\n",
    "\n",
    "# --------------------\n",
    "# Reproducibility\n",
    "# --------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# --------------------\n",
    "# Paths\n",
    "# --------------------\n",
    "IMAGES_PATH = \"../output/traffic_lights_images.npy\"\n",
    "LABELS_PATH = \"../output/traffic_lights_label.npy\"\n",
    "SAVE_DIR = \"../Models\"\n",
    "CKPT_DIR = os.path.join(SAVE_DIR, \"checkpoints\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "# Checkpoint cadence\n",
    "SAVE_EVERY = 2  # set 0 to disable periodic epoch_XXX saves\n",
    "\n",
    "# --------------------\n",
    "# cuDNN speedups\n",
    "# --------------------\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "def traffic_light_crop(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Black out the bottom third, blur and desaturate the left & right quarters.\n",
    "    Works for (H, W) grayscale or (H, W, C) RGB images.\n",
    "    Returns a copy with same shape/dtype.\n",
    "    \"\"\"\n",
    "    if img is None or img.ndim not in (2, 3):\n",
    "        return img\n",
    "\n",
    "    out = img.copy()\n",
    "    h, w = out.shape[:2]\n",
    "\n",
    "    # ---- Center zoom ----\n",
    "    z = 1.0 + (20.0 / 100.0)\n",
    "    new_w = max(1, int(w / z))\n",
    "    new_h = max(1, int(h / z))\n",
    "    x1 = max(0, (w - new_w) // 2)\n",
    "    y1 = max(0, (h - new_h) // 2)\n",
    "    cropped = out[y1:y1 + new_h, x1:x1 + new_w]\n",
    "    if cropped.size > 0:\n",
    "        out = cv2.resize(cropped, (w, h))\n",
    "\n",
    "    # --- Blackout bottom third ---\n",
    "    out[h * 2 // 3 :, ...] = 0\n",
    "\n",
    "    # --- Prepare for color manipulation ---\n",
    "    is_gray = (out.ndim == 2) or (out.shape[2] == 1)\n",
    "    if is_gray:\n",
    "        # Expand grayscale to 3 channels for consistent processing\n",
    "        out_rgb = cv2.cvtColor(out, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        out_rgb = out\n",
    "\n",
    "    quarter_w = max(1, w // 4)\n",
    "\n",
    "    def blur_and_desaturate(region: np.ndarray) -> np.ndarray:\n",
    "        # Blur\n",
    "        blurred = cv2.GaussianBlur(region, (21, 21), 0)\n",
    "        # # Convert to HSV for saturation adjustment\n",
    "        # hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "        # hsv[:, :, 1] = 0  # set saturation to zero (pure grayscale)\n",
    "        # desat = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        return blurred\n",
    "\n",
    "    # Left strip\n",
    "    out_rgb[:, :quarter_w, :] = blur_and_desaturate(out_rgb[:, :quarter_w, :])\n",
    "    # Right strip\n",
    "    out_rgb[:, -quarter_w:, :] = blur_and_desaturate(out_rgb[:, -quarter_w:, :])\n",
    "\n",
    "    # If original was grayscale, convert back\n",
    "    if is_gray:\n",
    "        out_final = cv2.cvtColor(out_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        out_final = out_rgb\n",
    "\n",
    "    return out_final\n",
    "\n",
    "# --------------------\n",
    "# Load data (NumPy)\n",
    "# --------------------\n",
    "X = np.load(IMAGES_PATH)  # (N,H,W) or (N,H,W,C)\n",
    "y_raw = np.load(LABELS_PATH)  # (N,) in {-1,0,1}\n",
    "\n",
    "if X.ndim not in (3, 4):\n",
    "    raise ValueError(f\"Expected images with 3 or 4 dims (N,H,W[,C]); got {X.shape}\")\n",
    "\n",
    "# >>> Apply traffic_light_crop to every image BEFORE any channel moves/normalization\n",
    "X = np.array([traffic_light_crop(x) for x in X], dtype=X.dtype)\n",
    "\n",
    "# Channel-first\n",
    "if X.ndim == 3:\n",
    "    X = np.expand_dims(X, axis=1)             # (N,1,H,W)\n",
    "else:\n",
    "    X = np.transpose(X, (0, 3, 1, 2))         # (N,C,H,W)\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "if X.max() > 1.5:\n",
    "    X /= 255.0\n",
    "\n",
    "# Labels {-1,0,1} -> {0,1,2}\n",
    "label_to_index = {-1: 0, 0: 1, 1: 2}\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "try:\n",
    "    y = np.vectorize(label_to_index.__getitem__)(y_raw)\n",
    "except KeyError as e:\n",
    "    raise ValueError(f\"Unknown label {e}; expected only -1, 0, 1\")\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# --------------------\n",
    "# Tensors\n",
    "# --------------------\n",
    "X_torch = torch.from_numpy(X).contiguous()                    # (N,C,H,W) float32\n",
    "y_torch = torch.from_numpy(y.astype(np.int64)).contiguous()   # (N,)\n",
    "\n",
    "# --------------------\n",
    "# Stratified split (80/20)\n",
    "# --------------------\n",
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    X_torch.numpy(), y_torch.numpy(),\n",
    "    test_size=0.2, random_state=SEED, stratify=y_torch.numpy(), shuffle=True\n",
    ")\n",
    "X_train = torch.from_numpy(X_train_np).contiguous()\n",
    "X_val   = torch.from_numpy(X_val_np).contiguous()\n",
    "y_train = torch.from_numpy(y_train_np).contiguous()\n",
    "y_val   = torch.from_numpy(y_val_np).contiguous()\n",
    "\n",
    "# --------------------\n",
    "# Transforms (RGB, 224, flip/rotate, cutout, ImageNet norm)\n",
    "# --------------------\n",
    "def to_rgb_tensor(x: torch.Tensor) -> torch.Tensor:\n",
    "    # x: (C,H,W) float in [0,1]\n",
    "    if x.dim() != 3:\n",
    "        raise ValueError(f\"Expected (C,H,W), got {tuple(x.shape)}\")\n",
    "    if x.shape[0] == 1:  # gray -> RGB\n",
    "        x = x.repeat(3, 1, 1)\n",
    "    elif x.shape[0] != 3:\n",
    "        raise ValueError(f\"Unsupported channels: {x.shape[0]}, expected 1 or 3.\")\n",
    "    return x\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Lambda(to_rgb_tensor),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=10, interpolation=InterpolationMode.BILINEAR, expand=False),\n",
    "    T.ToTensor(),\n",
    "    # blackout/cutout (chain for occasional multiple holes)\n",
    "    T.RandomErasing(p=0.5, scale=(0.02, 0.12), ratio=(0.3, 3.3), value=0.0, inplace=False),\n",
    "    T.RandomErasing(p=0.25, scale=(0.01, 0.06), ratio=(0.3, 3.3), value=0.0, inplace=False),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Lambda(to_rgb_tensor),\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# --------------------\n",
    "# Dataset wrapper\n",
    "# --------------------\n",
    "class AugmentedTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors, transform=None):\n",
    "        super().__init__(*tensors); self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        *xs, y = super().__getitem__(index)\n",
    "        x = xs[0]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "# --------------------\n",
    "# DataLoaders (Windows/Jupyter safe) + Balanced Sampler\n",
    "# --------------------\n",
    "def _workers():\n",
    "    is_windows = (os.name == \"nt\")\n",
    "    is_interactive = (\"ipykernel\" in sys.modules)\n",
    "    if is_windows or is_interactive:\n",
    "        return 0\n",
    "    c = os.cpu_count() or 2\n",
    "    return max(min(4, c - 1), 0)\n",
    "\n",
    "num_workers = _workers()\n",
    "persistent = True if num_workers > 0 else False\n",
    "\n",
    "train_ds = AugmentedTensorDataset(X_train, y_train, transform=train_transform)\n",
    "val_ds   = AugmentedTensorDataset(X_val,   y_val,   transform=val_transform)\n",
    "\n",
    "# ---- Balanced sampler to equalize exposure per class each epoch ----\n",
    "class_counts = np.bincount(y_train_np, minlength=num_classes).astype(np.float64)\n",
    "class_counts[class_counts == 0] = 1.0  # safety\n",
    "inv_freq = 1.0 / class_counts\n",
    "sample_weights = inv_freq[y_train_np]  # per-sample weights\n",
    "\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=torch.from_numpy(sample_weights).float(),\n",
    "    num_samples=len(y_train_np),  # approx one pass over \"balanced\" epoch\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=64, shuffle=False,    # shuffle must be False when sampler is set\n",
    "    sampler=train_sampler,\n",
    "    num_workers=num_workers, pin_memory=True, persistent_workers=persistent\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=64, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=True, persistent_workers=persistent\n",
    ")\n",
    "\n",
    "# Optional: quick look at sampled mix this epoch\n",
    "with torch.no_grad():\n",
    "    idxs = torch.tensor(list(train_sampler))\n",
    "epoch_counts = np.bincount(y_train_np[idxs.numpy()], minlength=num_classes)\n",
    "print(\"Sampled class counts (this epoch):\", epoch_counts.tolist(),\n",
    "      \" [order: index 0=-1 (no), 1=0 (red), 2=1 (green)]\")\n",
    "\n",
    "# --------------------\n",
    "# Model: ResNet-18 wrapped in ResNetClassifier (so keys are \"net.*\")\n",
    "# --------------------\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)  # expects 3ch\n",
    "        in_feat = backbone.fc.in_features\n",
    "        backbone.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_feat, num_classes))\n",
    "        self.net = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --------------------\n",
    "# Device & AMP\n",
    "# --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"AMP enabled:\", torch.cuda.is_available())\n",
    "\n",
    "model = ResNetClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "# --------------------\n",
    "# Loss / Optim / Scheduler\n",
    "# --------------------\n",
    "# With balanced sampling, do NOT also weight the loss (avoid double-compensation)\n",
    "class_weights = None\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n",
    "\n",
    "# two lrs: backbone vs head\n",
    "head_params = list(model.net.fc.parameters())\n",
    "backbone_params = [p for n, p in model.net.named_parameters() if not n.startswith(\"fc.\")]\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 1e-4},\n",
    "        {\"params\": head_params,     \"lr\": 3e-4},\n",
    "    ],\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "# --------------------\n",
    "# Checkpoint helpers\n",
    "# --------------------\n",
    "def _checkpoint_payload(epoch:int, best_val_loss:float, best_val_acc:float):\n",
    "    return {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"val_loss\": float(best_val_loss),\n",
    "        \"val_acc\": float(best_val_acc),\n",
    "        \"num_classes\": int(num_classes),\n",
    "        \"label_to_index\": label_to_index,\n",
    "        \"index_to_label\": index_to_label,\n",
    "        \"imagenet_mean\": IMAGENET_MEAN,\n",
    "        \"imagenet_std\": IMAGENET_STD,\n",
    "        \"seed\": SEED,\n",
    "    }\n",
    "\n",
    "def save_last(epoch, best_val_loss, best_val_acc):\n",
    "    path = os.path.join(CKPT_DIR, \"last.pth\")\n",
    "    torch.save(_checkpoint_payload(epoch, best_val_loss, best_val_acc), path)\n",
    "    print(f\"[ckpt] Saved last -> {path}\")\n",
    "\n",
    "def save_best(epoch, best_val_loss, best_val_acc):\n",
    "    path = os.path.join(CKPT_DIR, \"best.pth\")\n",
    "    torch.save(_checkpoint_payload(epoch, best_val_loss, best_val_acc), path)\n",
    "    print(f\"[ckpt] ✅ New best (val_loss={best_val_loss:.4f}) -> {path}\")\n",
    "\n",
    "def save_periodic(epoch, best_val_loss, best_val_acc):\n",
    "    if SAVE_EVERY and (epoch % SAVE_EVERY == 0):\n",
    "        path = os.path.join(CKPT_DIR, f\"epoch_{epoch:03d}.pth\")\n",
    "        torch.save(_checkpoint_payload(epoch, best_val_loss, best_val_acc), path)\n",
    "        print(f\"[ckpt] Saved periodic -> {path}\")\n",
    "\n",
    "# --------------------\n",
    "# Eval (returns loss, overall acc, per-class accs, macro acc)\n",
    "# --------------------\n",
    "SEMANTICS = { -1: \"no light\", 0: \"red\", 1: \"green\" }\n",
    "\n",
    "def per_class_metrics(all_targets, all_preds, num_classes):\n",
    "    cm = confusion_matrix(all_targets, all_preds, labels=list(range(num_classes)))\n",
    "    per_class_acc = cm.diagonal() / np.maximum(cm.sum(axis=1), 1)\n",
    "    macro = per_class_acc.mean() if len(per_class_acc) else 0.0\n",
    "    return per_class_acc, macro\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total, correct, run_loss = 0, 0, 0.0\n",
    "    all_t, all_p = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "            run_loss += loss.item() * yb.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "            all_t.append(yb.cpu().numpy()); all_p.append(preds.cpu().numpy())\n",
    "    all_t = np.concatenate(all_t) if all_t else np.array([])\n",
    "    all_p = np.concatenate(all_p) if all_p else np.array([])\n",
    "    per_cls, macro = per_class_metrics(all_t, all_p, num_classes) if all_t.size else (np.zeros(num_classes), 0.0)\n",
    "\n",
    "    # Pretty per-class print using label semantics\n",
    "    # index_to_label: {0:-1, 1:0, 2:1}\n",
    "    readable = []\n",
    "    for idx in range(num_classes):\n",
    "        raw_label = index_to_label[idx]\n",
    "        name = SEMANTICS[raw_label]\n",
    "        readable.append(f\"{name}={per_cls[idx]:.3f}\")\n",
    "    print(\"Per-class acc:\", \", \".join(readable), f\"| macro={macro:.3f}\")\n",
    "\n",
    "    return run_loss / max(total, 1), correct / max(total, 1), per_cls, macro\n",
    "\n",
    "# --------------------\n",
    "# Train\n",
    "# --------------------\n",
    "EPOCHS = 15\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state = None\n",
    "es_patience = 6\n",
    "es_wait = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    run_loss = 0.0; seen = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device, non_blocking=True); yb = yb.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        run_loss += loss.item() * yb.size(0); seen += yb.size(0)\n",
    "\n",
    "    train_loss = run_loss / max(seen, 1)\n",
    "    val_loss, val_acc, val_per_cls, val_macro = evaluate(val_loader)\n",
    "\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"[LR] reduced: {old_lr:.6g} -> {new_lr:.6g}\")\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | val_acc: {val_acc:.4f} | val_macro: {val_macro:.4f}\")\n",
    "\n",
    "    # Save \"last\" every epoch + periodic snapshots\n",
    "    save_last(epoch, best_val_loss, best_val_acc)\n",
    "    save_periodic(epoch, best_val_loss, best_val_acc)\n",
    "\n",
    "    # Track & save best by val_loss\n",
    "    if val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        best_state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"val_acc\": float(val_acc),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"num_classes\": int(num_classes),\n",
    "        }\n",
    "        save_best(epoch, best_val_loss, best_val_acc)\n",
    "        es_wait = 0\n",
    "    else:\n",
    "        es_wait += 1\n",
    "        if es_wait >= es_patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (no val_loss improvement for {es_patience} epochs).\")\n",
    "            break\n",
    "\n",
    "# --------------------\n",
    "# Final eval\n",
    "# --------------------\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state[\"model_state_dict\"])\n",
    "final_val_loss, final_val_acc, final_per_cls, final_macro = evaluate(val_loader)\n",
    "print(f\"Best validation loss:     {best_val_loss:.4f}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Final validation loss:    {final_val_loss:.4f}\")\n",
    "print(f\"Final validation accuracy:{final_val_acc:.4f}\")\n",
    "print(\"Final per-class acc:\",\n",
    "      f\"no-light={final_per_cls[0]:.4f}, red={final_per_cls[1]:.4f}, green={final_per_cls[2]:.4f}\",\n",
    "      f\"| macro={final_macro:.4f}\")\n",
    "\n",
    "# --------------------\n",
    "# Save artifacts (keys start with 'net.' -> matches testing script)\n",
    "# --------------------\n",
    "pth_path = os.path.join(SAVE_DIR, \"traffic_classifier_state.pth\")\n",
    "torch.save(best_state if best_state is not None else model.state_dict(), pth_path)\n",
    "print(f\"Saved state to: {pth_path}\")\n",
    "\n",
    "# TorchScript (scripted model expects 3x224x224 normalized)\n",
    "# Build a normalized example via val_transform\n",
    "ex = val_transform(X_val[:1].squeeze(0) if X_val[:1].ndim == 4 else X_val[:1])\n",
    "example = ex.unsqueeze(0).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scripted = torch.jit.trace(model, example)\n",
    "ts_path = os.path.join(SAVE_DIR, \"traffic_classifier_scripted.pt\")\n",
    "scripted.save(ts_path)\n",
    "print(f\"Saved TorchScript model to: {ts_path}\")\n",
    "\n",
    "# Class mapping & metrics\n",
    "with open(os.path.join(SAVE_DIR, \"class_mapping.json\"), \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"index_to_label\": {str(k): int(v) for k, v in index_to_label.items()},\n",
    "            \"label_to_index\": {str(k): int(v) for k, v in label_to_index.items()},\n",
    "            \"semantics\": {\"-1\": \"no light\", \"0\": \"red\", \"1\": \"green\"}\n",
    "        },\n",
    "        f,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, \"metrics.txt\"), \"w\") as f:\n",
    "    f.write(f\"Final validation accuracy: {final_val_acc:.4f}\\n\")\n",
    "    f.write(f\"Final validation loss: {final_val_loss:.4f}\\n\")\n",
    "    f.write(f\"Best validation accuracy: {best_val_acc:.4f}\\n\")\n",
    "    f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\")\n",
    "    f.write(f\"Per-class accuracy (no, red, green): \"\n",
    "            f\"{final_per_cls[0]:.4f}, {final_per_cls[1]:.4f}, {final_per_cls[2]:.4f} | macro={final_macro:.4f}\\n\")\n",
    "\n",
    "# --------------------\n",
    "# Prediction helper (applies same val pipeline)\n",
    "# --------------------\n",
    "def predict_labels_numpy(np_batch: np.ndarray, batch_size: int = 128) -> np.ndarray:\n",
    "    model.eval()\n",
    "    if np_batch.ndim == 3:\n",
    "        np_batch = np.expand_dims(np_batch, axis=0)\n",
    "    if np_batch.shape[-1] in (1,3) and np_batch.shape[1] not in (1,3):\n",
    "        np_batch = np.transpose(np_batch, (0,3,1,2))\n",
    "    if np_batch.dtype != np.float32:\n",
    "        np_batch = np_batch.astype(\"float32\")\n",
    "    if np_batch.max() > 1.5:\n",
    "        np_batch /= 255.0\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, np_batch.shape[0], batch_size):\n",
    "            chunk = torch.from_numpy(np_batch[i:i+batch_size])\n",
    "            batch_t = [val_transform(x) for x in chunk]  # ensure RGB+224+norm\n",
    "            batch_t = torch.stack(batch_t, dim=0).to(device, non_blocking=True)\n",
    "            logits = model(batch_t)\n",
    "            preds.append(logits.argmax(dim=1).cpu().numpy())\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return np.vectorize(index_to_label.__getitem__)(preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
