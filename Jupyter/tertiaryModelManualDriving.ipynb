{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e85a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\aadav/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Models/steering_model_final.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m SteeringClassifier()\n\u001b[1;32m---> 42\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Models/steering_model_final.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     45\u001b[0m image_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     46\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToPILImage(),\n\u001b[0;32m     47\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m                          std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[0;32m     51\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Models/steering_model_final.pth'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import carla\n",
    "import pygame\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from carla import VehicleLightState\n",
    "\n",
    "# Human-readable names for the 15 steering classes (strong left → no turn → strong right)\n",
    "CLASS_NAMES = [\n",
    "    \"Left Hardest\", \"Left Harder\", \"Left Hard\", \"Left Medium\", \"Left Light\", \"Left Slight\", \"Left Minimal\",\n",
    "    \"No Turning\",\n",
    "    \"Right Minimal\", \"Right Slight\", \"Right Light\", \"Right Medium\", \"Right Hard\", \"Right Harder\", \"Right Hardest\"\n",
    "]\n",
    "\n",
    "# ResNet18 backbone with a tiny head; turn signal goes through an embedding and is concatenated\n",
    "class SteeringClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super(SteeringClassifier, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()  # use the 512-d feature vector directly\n",
    "        self.cnn = resnet\n",
    "        self.turn_embed = nn.Embedding(3, 16)  # turn signals -1/0/1 are mapped to 0/1/2\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 + 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, turn_signal):\n",
    "        x_img = self.cnn(image)\n",
    "        x_signal = self.turn_embed(turn_signal)\n",
    "        x = torch.cat((x_img, x_signal), dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Load the trained classifier and switch to eval mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SteeringClassifier(num_classes=15)\n",
    "model.load_state_dict(torch.load(\"../Models/tertiary_model_final.pth\", map_location=device))\n",
    "model.eval().to(device)\n",
    "\n",
    "# Image preprocessing to 224x224 + ImageNet normalization\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Pygame window for the live camera view + HUD text\n",
    "pygame.init()\n",
    "width, height = 800, 600\n",
    "screen = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption(\"CARLA Model-Controlled Driving\")\n",
    "\n",
    "# Connect to the simulator and grab useful handles\n",
    "client = carla.Client(\"localhost\", 2000)\n",
    "client.set_timeout(25.0)\n",
    "client.load_world(\"Town05\")\n",
    "world = client.get_world()\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "\n",
    "# Spawn a Tesla Model 3 at a random spawn point and keep manual control\n",
    "vehicle_bp = blueprint_library.filter(\"vehicle.*model3*\")[0]\n",
    "spawn_point = random.choice(world.get_map().get_spawn_points())\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "vehicle.set_autopilot(False)\n",
    "\n",
    "# We’ll keep the spectator following behind the car\n",
    "spectator = world.get_spectator()\n",
    "\n",
    "# Add a front RGB camera to the vehicle\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '448')\n",
    "camera_bp.set_attribute('image_size_y', '252')\n",
    "camera_bp.set_attribute('fov', '145')\n",
    "camera_bp.set_attribute('sensor_tick', '0.1')\n",
    "cam_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "camera = world.spawn_actor(camera_bp, cam_transform, attach_to=vehicle)\n",
    "\n",
    "# Keep the latest frame as both a NumPy array (for the model) and a Pygame surface (for display)\n",
    "camera_image = None\n",
    "camera_np = None\n",
    "pred_label = \"Loading...\"\n",
    "\n",
    "def process_image(image):\n",
    "    global camera_image, camera_np\n",
    "    # CARLA gives BGRA bytes; convert to RGB NumPy and a Pygame surface\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    array = array.reshape((image.height, image.width, 4))\n",
    "    array = array[:, :, :3][:, :, ::-1]  # BGRA → RGB\n",
    "    camera_np = array.copy()\n",
    "    camera_image_raw = pygame.surfarray.make_surface(array.swapaxes(0, 1))\n",
    "    camera_image = pygame.transform.scale(camera_image_raw, (800, 600))\n",
    "\n",
    "# Start streaming camera frames\n",
    "camera.listen(process_image)\n",
    "\n",
    "# Small timing helper for the loop\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "print(\"Model-controlled driving started.\")\n",
    "print(\"Q/E to turn on left/right signal, R to cancel.\")\n",
    "print(\"ESC or close window to exit.\")\n",
    "\n",
    "# Map class IDs to steering values (range ~[-1, 1])\n",
    "steering_map = {\n",
    "    0: -1.0,   1: -0.8,   2: -0.6,   3: -0.4,   4: -0.25,  5: -0.15,  6: -0.05,\n",
    "    7:  0.0,\n",
    "    8:  0.05,  9:  0.15, 10:  0.25, 11:  0.4,  12:  0.6,  13:  0.8,  14:  1.0\n",
    "}\n",
    "\n",
    "# Main control loop: handle input, run the model, and apply vehicle commands\n",
    "try:\n",
    "    while True:\n",
    "        clock.tick(30)\n",
    "        pygame.event.pump()\n",
    "        keys = pygame.key.get_pressed()\n",
    "\n",
    "        # Turn signals: Q for left, E for right, R to clear; otherwise keep whatever is active\n",
    "        if keys[pygame.K_q]:\n",
    "            vehicle.set_light_state(VehicleLightState.LeftBlinker)\n",
    "            turn_signal = -1\n",
    "        elif keys[pygame.K_e]:\n",
    "            vehicle.set_light_state(VehicleLightState.RightBlinker)\n",
    "            turn_signal = 1\n",
    "        elif keys[pygame.K_r]:\n",
    "            vehicle.set_light_state(VehicleLightState.NONE)\n",
    "            turn_signal = 0\n",
    "        else:\n",
    "            light_state = vehicle.get_light_state()\n",
    "            if light_state == VehicleLightState.LeftBlinker:\n",
    "                turn_signal = -1\n",
    "            elif light_state == VehicleLightState.RightBlinker:\n",
    "                turn_signal = 1\n",
    "            else:\n",
    "                turn_signal = 0\n",
    "\n",
    "        # Ask the model for a steering class and convert it to a steering value\n",
    "        control = carla.VehicleControl()\n",
    "        control.throttle = 0.3\n",
    "\n",
    "        if camera_np is not None:\n",
    "            with torch.no_grad():\n",
    "                img = image_transform(camera_np).unsqueeze(0).to(device)\n",
    "                signal = torch.tensor([[turn_signal + 1]], dtype=torch.long).to(device)\n",
    "                output = model(img, signal.squeeze(1))\n",
    "                pred_class = output.argmax(dim=1).item()\n",
    "                pred_label = CLASS_NAMES[pred_class]\n",
    "                control.steer = steering_map[pred_class]\n",
    "\n",
    "        vehicle.apply_control(control)\n",
    "\n",
    "        # Keep the spectator camera trailing the car a few meters back and a bit above\n",
    "        car_transform = vehicle.get_transform()\n",
    "        forward_vector = car_transform.get_forward_vector()\n",
    "        cam_location = car_transform.location - forward_vector * 8 + carla.Location(z=3)\n",
    "        cam_rotation = carla.Rotation(pitch=-10, yaw=car_transform.rotation.yaw)\n",
    "        spectator.set_transform(carla.Transform(cam_location, cam_rotation))\n",
    "\n",
    "        # Draw the live camera view and the predicted class\n",
    "        if camera_image:\n",
    "            screen.blit(camera_image, (0, 0))\n",
    "            font = pygame.font.SysFont(None, 30)\n",
    "            label_surface = font.render(f\"Predicted: {pred_label}\", True, (255, 255, 0))\n",
    "            screen.blit(label_surface, (20, 20))\n",
    "            pygame.display.flip()\n",
    "\n",
    "        # Close the window or hit ESC to exit cleanly\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT or keys[pygame.K_ESCAPE]:\n",
    "                raise KeyboardInterrupt\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting and cleaning up...\")\n",
    "\n",
    "finally:\n",
    "    camera.stop()\n",
    "    vehicle.destroy()\n",
    "    camera.destroy()\n",
    "    pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
