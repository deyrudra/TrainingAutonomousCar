{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b0e94f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './30.01_quinary_model_final.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m SteeringVelocityNet(num_steering_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./30.01_quinary_model_final.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     54\u001b[0m image_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     55\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToPILImage(),\n\u001b[0;32m     56\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m                          std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[0;32m     60\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\aadav\\anaconda3\\envs\\ACS\\lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './30.01_quinary_model_final.pth'"
     ]
    }
   ],
   "source": [
    "import carla\n",
    "import pygame\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from carla import VehicleLightState\n",
    "\n",
    "# === Model Class Labels ===\n",
    "CLASS_NAMES = [\n",
    "    \"Left Hardest\", \"Left Harder\", \"Left Hard\", \"Left Medium\", \"Left Light\", \"Left Slight\", \"Left Minimal\",\n",
    "    \"No Turning\",\n",
    "    \"Right Minimal\", \"Right Slight\", \"Right Light\", \"Right Medium\", \"Right Hard\", \"Right Harder\", \"Right Hardest\"\n",
    "]\n",
    "\n",
    "# === PyTorch Model Definition ===\n",
    "class SteeringVelocityNet(nn.Module):\n",
    "    def __init__(self, num_steering_classes=15):\n",
    "        super(SteeringVelocityNet, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()\n",
    "        self.cnn = resnet\n",
    "\n",
    "        self.turn_embed = nn.Embedding(3, 16)\n",
    "\n",
    "        self.shared_fc = nn.Sequential(\n",
    "            nn.Linear(512 + 16, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.steering_head = nn.Linear(128, num_steering_classes)\n",
    "        self.velocity_head = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, image, turn_signal):\n",
    "        x_img = self.cnn(image)\n",
    "        x_signal = self.turn_embed(turn_signal)\n",
    "        x = torch.cat((x_img, x_signal), dim=1)\n",
    "\n",
    "        shared = self.shared_fc(x)\n",
    "        steering_out = self.steering_head(shared)\n",
    "        velocity_out = self.velocity_head(shared)\n",
    "\n",
    "        return steering_out, velocity_out.squeeze(1)\n",
    "\n",
    "# === Initialize PyTorch Model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SteeringVelocityNet(num_steering_classes=15)\n",
    "model.load_state_dict(torch.load(\"./30.01_quinary_model_final.pth\", map_location=device))\n",
    "model.eval().to(device)\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# === Pygame Setup ===\n",
    "pygame.init()\n",
    "width, height = 800, 600\n",
    "screen = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption(\"CARLA Model-Controlled Driving\")\n",
    "\n",
    "# === Connect to CARLA ===\n",
    "client = carla.Client(\"localhost\", 2000)\n",
    "client.set_timeout(25.0)\n",
    "client.load_world(\"Town01\")\n",
    "world = client.get_world()\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "\n",
    "# === Spawn Vehicle ===\n",
    "vehicle_bp = blueprint_library.filter(\"vehicle.mini.cooper_s_2021\")[0]\n",
    "spawn_point = random.choice(world.get_map().get_spawn_points())\n",
    "vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "vehicle.set_autopilot(False)\n",
    "\n",
    "# === Spectator Setup ===\n",
    "spectator = world.get_spectator()\n",
    "\n",
    "# === Attach Camera Sensor ===\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '448')\n",
    "camera_bp.set_attribute('image_size_y', '252')\n",
    "camera_bp.set_attribute('fov', '145')\n",
    "camera_bp.set_attribute('sensor_tick', '0.1')\n",
    "cam_transform = carla.Transform(carla.Location(x=1.5, z=2.4))\n",
    "camera = world.spawn_actor(camera_bp, cam_transform, attach_to=vehicle)\n",
    "\n",
    "# Shared variables\n",
    "camera_image = None\n",
    "camera_np = None\n",
    "pred_label = \"Loading...\"\n",
    "\n",
    "def process_image(image):\n",
    "    global camera_image, camera_np\n",
    "    array = np.frombuffer(image.raw_data, dtype=np.uint8)\n",
    "    array = array.reshape((image.height, image.width, 4))\n",
    "    array = array[:, :, :3][:, :, ::-1]  # RGB\n",
    "    camera_np = array.copy()\n",
    "    camera_image_raw = pygame.surfarray.make_surface(array.swapaxes(0, 1))\n",
    "    camera_image = pygame.transform.scale(camera_image_raw, (800, 600))\n",
    "\n",
    "camera.listen(process_image)\n",
    "\n",
    "# === Clock ===\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "print(\"Model-controlled driving started.\")\n",
    "print(\"Q/E to turn on left/right signal, R to cancel.\")\n",
    "print(\"ESC or close window to exit.\")\n",
    "\n",
    "# === Steering Mapping for 15 Classes ===\n",
    "steering_map = {\n",
    "    0: -0.8,   1: -0.6,   2: -0.4,   3: -0.25,   4: -0.20,  5: -0.1,  6: -0.05,\n",
    "    7:  0.0,\n",
    "    8:  0.05,  9:  0.1, 10:  0.15, 11:  0.25,  12:  0.4,  13:  0.6,  14:  0.8\n",
    "}\n",
    "\n",
    "# === Main Loop ===\n",
    "try:\n",
    "    prev_steering_value = 0.0\n",
    "    last_steering_time = time.time()\n",
    "    STEERING_HOLD_S = 0.05  # 50 ms\n",
    "\n",
    "    while True:\n",
    "        clock.tick(60)\n",
    "        pygame.event.pump()\n",
    "        keys = pygame.key.get_pressed()\n",
    "\n",
    "        # Turn signal input (Q/E/R)\n",
    "        if keys[pygame.K_q]:\n",
    "            vehicle.set_light_state(VehicleLightState.LeftBlinker)\n",
    "            turn_signal = -1\n",
    "        elif keys[pygame.K_e]:\n",
    "            vehicle.set_light_state(VehicleLightState.RightBlinker)\n",
    "            turn_signal = 1\n",
    "        elif keys[pygame.K_r]:\n",
    "            vehicle.set_light_state(VehicleLightState.NONE)\n",
    "            turn_signal = 0\n",
    "        else:\n",
    "            light_state = vehicle.get_light_state()\n",
    "            if light_state == VehicleLightState.LeftBlinker:\n",
    "                turn_signal = -1\n",
    "            elif light_state == VehicleLightState.RightBlinker:\n",
    "                turn_signal = 1\n",
    "            else:\n",
    "                turn_signal = 0\n",
    "\n",
    "        # === Predict and Control ===\n",
    "        control = carla.VehicleControl()\n",
    "\n",
    "        if camera_np is not None:\n",
    "            with torch.no_grad():\n",
    "                img = image_transform(camera_np).unsqueeze(0).to(device)\n",
    "                signal = torch.tensor([[turn_signal + 1]], dtype=torch.long).to(device)\n",
    "\n",
    "                steering_logits, velocity_pred = model(img, signal.squeeze(1))\n",
    "\n",
    "                pred_class = steering_logits.argmax(dim=1).item()\n",
    "                pred_label = CLASS_NAMES[pred_class]\n",
    "                steering_value = steering_map[pred_class]\n",
    "\n",
    "                # Enforce minimum turn for active signal\n",
    "                if turn_signal == -1 and steering_value > -0.02:\n",
    "                    steering_value = -0.02\n",
    "                elif turn_signal == 1 and steering_value < 0.02:\n",
    "                    steering_value = 0.02\n",
    "\n",
    "                # === Steering Smoothing ===\n",
    "                current_time = time.time()\n",
    "                if steering_value == 0.0 or prev_steering_value == 0.0:\n",
    "                    control.steer = steering_value\n",
    "                    prev_steering_value = steering_value\n",
    "                    last_steering_time = current_time\n",
    "                elif steering_value != prev_steering_value:\n",
    "                    control.steer = (steering_value + prev_steering_value) / 2\n",
    "                    prev_steering_value = steering_value\n",
    "                    last_steering_time = current_time\n",
    "                else:\n",
    "                    if current_time - last_steering_time >= STEERING_HOLD_S:\n",
    "                        control.steer = steering_value\n",
    "\n",
    "                # === Velocity Control ===\n",
    "                velocity_value = velocity_pred.item()\n",
    "                velocity_value = max(0.0, min(velocity_value, 1.0))  # Clamp\n",
    "                control.throttle = velocity_value\n",
    "                control.brake = 0.0 if velocity_value > 0.05 else 0.3\n",
    "\n",
    "        vehicle.apply_control(control)\n",
    "\n",
    "        # === Spectator follows vehicle ===\n",
    "        car_transform = vehicle.get_transform()\n",
    "        forward_vector = car_transform.get_forward_vector()\n",
    "        cam_location = car_transform.location - forward_vector * 8 + carla.Location(z=3)\n",
    "        cam_rotation = carla.Rotation(pitch=-10, yaw=car_transform.rotation.yaw)\n",
    "        spectator.set_transform(carla.Transform(cam_location, cam_rotation))\n",
    "\n",
    "        # === Display Feed + Prediction ===\n",
    "        if camera_image:\n",
    "            screen.blit(camera_image, (0, 0))\n",
    "            font = pygame.font.SysFont(None, 30)\n",
    "            label_surface = font.render(f\"Predicted: {pred_label}\", True, (255, 255, 0))\n",
    "            screen.blit(label_surface, (20, 20))\n",
    "            pygame.display.flip()\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT or keys[pygame.K_ESCAPE]:\n",
    "                raise KeyboardInterrupt\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting and cleaning up...\")\n",
    "\n",
    "finally:\n",
    "    camera.stop()\n",
    "    vehicle.destroy()\n",
    "    camera.destroy()\n",
    "    pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
