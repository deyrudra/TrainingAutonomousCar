\documentclass{article} % For LaTeX2e
\usepackage{iclr2022_conference,times}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%######## APS360: Uncomment your submission name
\newcommand{\apsname}{Project Proposal}
%\newcommand{\apsname}{Progress Report}
%\newcommand{\apsname}{Final Report}

%######## APS360: Put your Group Number here
\newcommand{\gpnumber}{4}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{float}
\restylefloat{table}

%######## APS360: Put your project Title here
\title{Formatting Instructions for APS360 Project  \\ 
based on ICLR Conference Format}


%######## APS360: Put your names, student IDs and Emails here
\author{Rudra Dey  \\
Student\# 1010124866\\
\texttt{rudra.dey@mail.utoronto.ca } \\
\And
Pravin Kalaivannan  \\
Student\# 1010141295 \\
\texttt{pravin.kalaivannan@mail.utoronto.ca} \\
\AND
Aadavan Vasudevan  \\
Student\# 1010101514 \\
\texttt{aadavan.vasudevan@mail.utoronto.ca} \\
\And
Abishan Baheerathan \\
Student\# 1010218756 \\
\texttt{abishan.baheerathan@mail.utoronto.ca} \\
\AND
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy 
%######## APS360: Document starts here
\begin{document}


\maketitle

\begin{abstract}
This template should be used for all your project related reports in APS360 course. -- Write an abstract for your project here. Please review the \textbf{ First Course Tutorial} for a quick start
%######## APS360: Do not change the next line. This shows your Main body page count.
----Total Pages: \pageref{last_page}
\end{abstract}



\section{Project Document Submission for APS360 Course}


The format for the submissions is a variant of the ICLR 2022 format.
Please read carefully the instructions below, and follow them
faithfully. There is a \textbf{9 page} limit for the main text. References do not have any limitation. This is also ICLR's standard length for a paper submission. 
If your main text goes to page 10, a $-20\%$ penalty would be applied. If your main text goes to page 11, you will not receive any grade for your submission. 

\subsection{Style}

Papers to be submitted to APS360 must be prepared according to the
instructions presented here.

Authors are required to use the APS360 \LaTeX{} style files obtainable at the
APS360 website on Quercus. Tweaking the style is not permitted.

\subsection{Retrieval of style files}

The file \verb+APS360_Project.pdf+ contains these
instructions and illustrates the various formatting requirements your APS360 paper must satisfy.
Submissions must be made using \LaTeX{} and the style files
\verb+iclr2022_conference.sty+ and \verb+iclr2022_conference.bst+ (to be used with \LaTeX{}2e). The file
\verb+APS360_Project.tex+ may be used as a ``shell'' for writing your paper. All you have to do is replace the author, title, abstract, and text of the paper with
your own.

The formatting instructions contained in these style files are summarized in
sections \ref{gen_inst}, \ref{headings}, and \ref{others} below.

\section{General formatting instructions}
\label{gen_inst}

The text must be confined within a rectangle 5.5~inches (33~picas) wide and
9~inches (54~picas) long. The left margin is 1.5~inch (9~picas).
Use 10~point type with a vertical spacing of 11~points. Times New Roman is the
preferred typeface throughout. Paragraphs are separated by 1/2~line space,
with no indentation.

Paper title is 17~point, in small caps and left-aligned.
All pages should start at 1~inch (6~picas) from the top of the page.

Authors' names are
set in boldface, and each name is placed above its corresponding
address. The lead author's name is to be listed first, and
the co-authors' names are set to follow. Authors sharing the
same address can be on the same line.

Please pay special attention to the instructions in section \ref{others}
regarding figures, tables, acknowledgments, and references.


There will be a strict upper limit of 9 pages for the main text of the initial submission, with unlimited additional pages for citations. 

\section{Background and Related Works}
\label{headings}

\subsection{Autonomous RC Car Related Projects}

Through the use of deep learning, many autonomous car projects have been developed and tested, showing the potential of this technology in real-world applications. 
The following is an overview of five works related to autonomous vehicles using deep learning.  


\subsubsection{Deep CNN End-to-End Learning for Autonomous RC Cars \citep{bhutta2023deep}}

 
In this study, end-to-end learning using deep convolutional neural networks (CNNs) was used to autonomously control an RC car around a race track. 
A front-facing camera is used to collect images of the car’s view, which is fed to the model. The CNN extracts features through convolutional and poling layers, 
then applies the nonlinear ReLU activation function, which is then passed through 3 fully connected layers to generate the output of necessary steering angles 
and speed the car needs to travel \citep{bhutta2023deep}.

\subsubsection{Autonomous RC Car Using Neural Networks \citep{Mallik2023}}

This project explores autonomous driving through a small RC car using a Raspberry Pi and a CNN based end-to-end steering angle prediction system. 
To train the model, the car was manually driven around a track and the Raspberry Pi was used to track the analog steering inputs along with recording video frames 
taken at 10-20 fps. The project highlights limited computing resources from the Pi’s onboard chips which may constrain CNN complexity along with data 
diversity being an issue where overfitting to a single environment leads to issues in other environments. Additionally, the project highlights the 
feasibility of deep learning for autonomous navigation and that it can be scaled up to larger robotic systems.

\subsubsection{Development of Single-board Computer-based Self-Driving Car Model \citep{9751873}}

In this paper, an RC car based on the DonkeyCar project, powered by a Nvidia Jetson Nano and controlled by a CNN was used to drive autonomously around a track. The
CNN uses live photos of the car’s front view to predict the steering angle and speed required. The authors created varied training set sizes of 
3000, 6000, 12000 and 24000 along with variations of network depth of between two and five layers of convolutional layers to find the best model \citep{9751873}. 
Their results showed that the model with 24000 images with three convolution layers performed the best with an absolute error at 0.18257 \citep{9751873}. 
Additionally, the results showed that having more data consistently reduced error, while adding layers above three had diminishing returns. 


\subsubsection{CNN based End to End Learning Steering Angle Prediction for Autonomous Electric Vehicles \citep{Mygapula2021}}

This paper explores CNN based end-to-end learning for steering angle prediction in autonomous vehicles using images captured of the front 
view of the car which is passed through to the model in a Jetson TX1. The team trained 3 different models based on different CNN architectures 
with different numbers of layers and the results showed that the CNN model with 4 CNN layers and 4 connected layers performed the 
best with 0.0354 test loss \citep{Mygapula2021}. These results highlight the viability of CNNs in learning steering behaviours compared to typical 
approaches in which systems are broken into multiple stages (such as road and object detection, and path planning)as it has fewer potential failure points.

\subsubsection{End to End Learning for Self-Driving Cars \citep{bojarski2016endendlearningselfdriving}}

In this paper, the team trained a CNN to map raw pixels from a front-facing camera directly to steering commands for a car. 
The network made up of nine layers, with one normalization layer, five convolutional layers and three fully connected layers 
was trained to minimize the mean squared error between steering commands and the human driver’s inputs. Using only 
72 hours of driving data, the team was able to successfully train the car to operate in diverse conditions showing 
how a CNN can perform the entire task without manual decomposition into smaller systems. 

\section{Data Processing}
\label{headings}


The Data Processing pipeline for the self-driving car project has three critical phases:
Data Collection, Data Cleaning and Preprocessing, and Dataset Splitting. These phases are
needed to ensure a proper and high quality training, validation, and testing of our model.

\subsection{Data Collection}

\subsubsection{Public Datasets}
\begin{itemize}
  \item Udacity Self-Driving Car Dataset
  \item Berkeley DeepDrive (BDD100K)
\end{itemize}

\subsubsection{Custom Data Collection}
\begin{itemize}
  \item Simulated Data: Using CARLA Simulator to generate high-resolution images with corresponding control commands.
  \item Real-World Data: Dash-mounted Camera on RC Cars.
\end{itemize}


\subsection{Data Cleaning and Preprocessing}

This phase involves preparing the image data and labels to reduce maximize model accuracy. 
This includes image normalization, label consistency checks.

\subsubsection{Remove Corrupted or Blurry Frames}
Removal of incomplete metadata, heavy blur, overexposure, and distorted images using automated filters.
These filters include: Laplacian Variance for blur detection, Histogram Analysis for overexposure, 
and Pixel Clipping Detection.


\subsubsection{Image Resizing and Normalization}
All images are resized to uniform size of 320x240 pixels to match input expectation for deep CNNs. Additionally, 
pixel values are normalizedto seed up convergence during training.

\subsubsection{Label Alignment and Verification}
Control labels are synchronized with their corresponding images using timestamps. Outliers and inconsistent 
data are flagged and removed. 

\subsection{Dataset Splitting}
The dataset is split into:
\begin{itemize}
  \item 80\% Training
  \item 10\% Validation 
  \item 10\% Testing 
\end{itemize}

Since we are using data that comes from continuous streams, randomly shuffling data could have
it so very similar frames of the stream can land in training, validation, and testing leading to 
memorization of the data. Thus, we will split the data chronologically, first 80\% goes to 
training, the next 10\% goes to validation, and the last 10\% goes to testing. 

\section{Architecture}

\section{Baseline Model}

A hand-coded rule-based controller serves as a reasonable baseline for evaluating the performance of the autonomous RC car. 
This baseline model simulates traditional line-following logic, where decisions are made using simple heuristics based off of 
pixel color thresholds and pre-defined turning logic \citep{LIKMETA2020103568}. The rule-based controller follows a deterministic flow, first, the incoming 
video frame is converted to grayscale or HSV color space, and then a threshold is applied to detect the track line (usually a black line 
on a white surface or vice versa) \citep{LIKMETA2020103568}. The centroid of the detected line is computed, and based on its position relative to the image center, 
turning decisions are made. For example, steering left if the line is on the left half of the image, right if on the right half, and forward if 
centered \citep{bojarski2016endendlearningselfdriving}. This model does not involve learning or generalization; it is purely reactive and works well in constrained, consistent environments 
with high-contrast tracks. While simplistic, this approach is widely used as a baseline in autonomous driving projects due to its reproducibility 
and interpretability.

\section{Ethical Considerations}

\subsection{Model Usage}
Since this project involves physical hardware operating in real-time, safety is a primary concern. The model may make poor decisions in edge cases 
(obstacles, unfamiliar lighting conditions), which could lead to hardware damage or unintended collisions \citep{dalrymple2024guaranteedsafeaiframework}. If used as part of a demonstration 
involving human interaction, ensuring safety measures (kill switches, limited speed) is essential. Another ethical concern is over-reliance on the 
model's predictions. If used in future deployments (real vehicles or educational kits), assuming the trained model can handle all situations without 
proper validation may mislead users and cause harm or accidents \citep{laskey2017comparinghumancentricrobotcentricsampling}. 


\subsection{Data Collection}
The data used for imitation learning is sourced from human demonstrations. A bias may arise if only a single driving style or track layout is captured.
For instance, if the human driver consistently takes tight turns or drives aggressively, the model may learn to imitate that behavior, limiting 
generalization to new tracks or drivers. Additionally, reinforcement learning episodes are generated in a simulated or controlled environment 
\citep{laskey2017comparinghumancentricrobotcentricsampling}. 
This might restrict the model's robustness in diverse real-world settings. Ethical considerations also include ensuring no unnecessary wear is inflicted 
on hardware during data collection or that any modifications to the car setup are clearly documented and standardized.

\section{Project Plan}
To ensure the seamless progression of the project and collaboration among team members, we have devised guidelines and a timeline as seen below.

\subsection{Team Guidelines}

\begin{table}[H]
\caption{Meeting Specifications}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\textbf{Meeting Guidelines} & \textbf{Details} \\ \hline
In-person meeting           & Location and time decided by the team \\ \hline
Online meetings             & Tuesdays (3-5 pm) and Saturdays (1-3 pm) \\ \hline
Absence Notification        & Must notify team 24 hours before meeting if absence will occur \\ \hline
\end{tabular}
\end{center}
\end{table}

\textbf{Communication Guidelines}
\begin{itemize}
  \item Group chat is active on weekdays and weekends (24/7)
  \item Group chat is active on weekdays and weekends (24/7)
  \item Members are required to frequently check discord messages (less than 2 hour response time)
\end{itemize}

\textbf{Collaboration Guidelines}
\begin{itemize}
  \item The team will be working together in a Github repository
  \item Each member is required to give a daily update message on their progress
  \item If conflicts arise, the team must discuss them together and decide on a solution that makes everyone happy
  \item Ensure code has informational comments that help the team understand it
\end{itemize}

\subsection{Project Timeline}



\section{Risk Register}
The risk register contains some scenarios that could negatively impact our project. 
These potential risks negatively affect deadlines, quality of work, and more. Our team has 
discussed these scenarios and came up with solutions for each project risk. 

\begin{table}[H]
\caption{Project Risks}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Project Risk}                                                                           & \textbf{Likelihood} & \textbf{Solution}                                                                                                                                                                                                                                                                                                               \\ \hline
A teammate drops the course                                                                     & Unlikely            & \begin{tabular}[c]{@{}l@{}}The team has to approach splitting up tasks differently \\ as teammates will now have more responsibilities. \\ We have to start tasks earlier and move internal \\ deadlines to an earlier date because each member has \\ more tasks to complete\end{tabular}                                      \\ \hline
\begin{tabular}[c]{@{}l@{}}Model training takes longer \\ than expected\end{tabular}            & Likely              & \begin{tabular}[c]{@{}l@{}}It’s common to procrastinate on less important or easier \\ tasks, so this would be the time to complete them. \\ The team should start working on tasks earlier, so \\ if this does occur it doesn’t affect project deadlines\end{tabular}                                                          \\ \hline
\begin{tabular}[c]{@{}l@{}}Experience hardware problems \\ during testing\end{tabular}          & Likely              & \begin{tabular}[c]{@{}l@{}}The team should keep extra hardware components in \\ case they fail during testing stages. Also, try not to \\ overuse the physical components, and use simulation \\ software to test\end{tabular}                                                                                                  \\ \hline
\begin{tabular}[c]{@{}l@{}}Model works in simulation \\ but not on physical RC car\end{tabular} & Likely              & \begin{tabular}[c]{@{}l@{}}We shouldn’t fully rely on simulations, and should \\ test the model on the physical RC car frequently. \\ The earlier the team faces these issues, the longer \\ we have to fix them. Compare the results from \\ simulation and physical RC car and that might \\ help solve problems\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}A teammate misses an internal \\ deadline\end{tabular}               & Likely              & \begin{tabular}[c]{@{}l@{}}The team should hold everyone accountable as each \\ member is responsible for their assigned tasks. \\ The teammate should finish tasks as soon as possible \\ after the missed deadline because this will \\ hold back the team\end{tabular}                                                       \\ \hline
\end{tabular}
\end{table}


\section{Final instructions}
Do not change any aspects of the formatting parameters in the style files.
In particular, do not modify the width or length of the rectangle the text
should fit into, and do not change font sizes (except perhaps in the
\textsc{References} section; see below). Please note that pages should be
numbered.


\subsubsection*{Author Contributions}
If you'd like to, you may include  a section for author contributions as is done
in many journals. This is optional and at the discretion of the authors.

\subsubsection*{Acknowledgments}
Use unnumbered third level headings for the acknowledgments. All
acknowledgments, including those to funding agencies, go at the end of the paper.

\label{last_page}

\bibliography{APS360_ref}
\bibliographystyle{iclr2022_conference}

\end{document}
