\documentclass{article} % For LaTeX2e
\usepackage{iclr2022_conference,times}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%######## APS360: Uncomment your submission name
\newcommand{\apsname}{Project Progress Report}
%\newcommand{\apsname}{Progress Report}
%\newcommand{\apsname}{Final Report}

%######## APS360: Put your Group Number here
\newcommand{\gpnumber}{4}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{float}
\restylefloat{table}

%######## APS360: Put your project Title here
\title{Progress Report: AUTONOMOUS CAR USING CNN\\}


%######## APS360: Put your names, student IDs and Emails here
\author{Rudra Dey  \\
Student\# 1010124866\\
\texttt{rudra.dey@mail.utoronto.ca } \\
\And
Pravin Kalaivannan  \\
Student\# 1010141295 \\
\texttt{pravin.kalaivannan@mail.utoronto.ca} \\
\AND
Aadavan Vasudevan  \\
Student\# 1010101514 \\
\texttt{aadavan.vasudevan@mail.utoronto.ca} \\
\And
Abishan Baheerathan \\
Student\# 1010218756 \\
\texttt{abishan.baheerathan@mail.utoronto.ca} \\
\AND
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy 
%######## APS360: Document starts here
\begin{document}

\maketitle

\begin{abstract}
This document presents our team's procedure to create the baseline model
code for an autonomous self-driving car. ...\\

\end{abstract}

\section{Project Description}

\section{Individual Contributions and Responsibilities}

\subsection{Individual Contributions}

\section{Data Processing}

Data was collected from the CARLA simulator, including images and corresponding steering values. We then normalized the images allowing us to train our CNN.
Further, data augmentation was applied to increase the size and diversity of the dataset, leading to better generalization of the model.


\subsection{Data Collection and Cleaning}

In CARLA, there is vehicles that have autonomous functionality, which we used to collect data.
We attached an RGB Camera Sensor to the car to record 10 frames per second (FPS) as the car
travels around a designated map. In addition to the images, data for the steering values and turn signals of the car
was collected allowing for use as ground truth labels for training the model. This data collection was done on diffreent maps with different weather conditions
to ensure a diverse dataset. We collected samples on eight maps, in which the car collected data for 30 minitues, resulting in 14400 total images.


To clean the data, we removed any images that were all black, duplicates or not the correct resolution of 320x240 leaving us with 14239 images.  We then saved 
the data as numpy arrays, zipped and uploaded to a shared Google Colab file along, ensuring access for all members. 

Procedure:
\begin{enumerate}
  \item{Spawn in a vehicle}
  \item{Attach an RGB Camera Sensor (front-facing) to the dash of the car.}
  \item{Collect image data (10 fps) along with steering data and turn signals.}
  \item {Clean the data by removing corrupted images and duplicates.}
  \item {Save the data as numpy arrays for easy access and processing.}
\end{enumerate}


\subsection{Data Preprocessing}
All collected images were resized to a resolution of 160x120 pixels, with the pixel values normalized to a range of [0, 1]. 
This was done to ensure consistency in the input data  

\subsection{Data Agumentation}

\subsection{Plan for Testing on Unseen Data}

\subsection{Challeneges Faced and Solutions}


Data will  be collected without traffic in the roads (i.e
no pedestrians or cars on the road). The car would have a constant speed
and the camera will always be mounted in the same position and angle at
the front of the car. The FPS will be set to a constant 20 FPS.
We will use the CARLA's autopilot to gain the steering values necessary to be used as ground truth labels. To get a diverse
set of data, we will collect data in different maps and weather conditions.







 
\section{Creating Baseline Model}

This baseline model will predict steering angles from grayscale images for an autonomous
vehicle simulator (which already has a autopilot built in). 

The following libraries will be used:
\begin{enumerate}
  \item numpy: For numerical operations on arrays
  \item matplotlib: For visualization of data
  \item scikit-learn: For machine learning components
  \begin{enumerate}
    \item Ridge: A regularized linear regression model
    \item MSE: Mean Square Error for evaluation metrics
    \item train\_test\_split: For data splitting
  \end{enumerate}
\end{enumerate}

The data will be loaded using two numpy arrays: images.npy and angles.npy. The images.npy
will contain N grayscale images of resolutions 160x120, and the angles will have the corresponding
images steering angles (of the car) in a range from [-1,1]. This makes it so the image data is 
represented as 3D arrays of samples x hieght x width as the dimension. The steering angles are
continuous (regression problem). 

The images will be flattened from their 2D representation of 160x120 matrix to a 1D representation
of 19200 vectors. Where each image becomes a single row in a feature matrix. Additionally,
we will split do a 80-20 train-test split.

The baseline model will be a ridge regression model. The ridge regression model is basically, the
same as a linear regression model except, it regularizes large weights. It adds an L2 penality to
discourage large weights, this helps with overfitting. The same as linear regression as we try to
fit: $\hat{y} = Xw + b$, but now we try to minimize the loss function: $LOSS = MSE + \alpha 
||\omega||^2_2$. The model will learn the weights corresponding to each pixel's contribution to 
steering.

We will compute two metrics, the mean square error (MSE) and the $R^2$ score (proportion of variance). 





\subsection{Building the model}

\subsection{Evaluating the model}



\section{Training Neural Netowrk}

*Quantitative Results: Training Loss (MSE) and Validation Loss

\subsection{Model Training Script}

\subsection{Logging}

\subsection{Outputting Results}



\section{Evaluating with Inference}

*Qualitative Results: Using model for actual driving in CARLA

\subsection{Running model in CARLA using live camera feed}


\end{document}
